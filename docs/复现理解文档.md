# Active-H-EMV 项目深度复现理解文档

> **核心目标**：不只是"跑起来"，而是真正理解这个系统"在做什么"、"为什么这样做"

---

## 📋 复现理解模板

### 1️⃣ 这个项目在解决什么问题？

**一句话概括**：
让机器人能够用自然语言回答关于它**一生经历**（几个月、几年）的问题，而不仅仅是几分钟的短期记忆。

**核心挑战**：
- 传统方法：只能处理几分钟的数据，无法扩展到长时记忆
- 计算成本：如果把所有原始数据都给 LLM，成本爆炸
- 检索精度：如何在海量数据中快速找到相关信息

**解决方案**：
构建一个**分层的树形记忆结构**，让 LLM 像"搜索图书馆"一样，先看目录（高层摘要），再根据需要展开细节（低层原始数据）。

---

### 2️⃣ 系统结构图（核心数据流）

```
┌─────────────────────────────────────────────────────────┐
│                    用户问题                              │
│            "机器人昨天做了什么？"                         │
└──────────────────┬──────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────┐
│           LLM Agent (互动搜索控制器)                     │
│   - 分析问题                                             │
│   - 决定搜索策略                                         │
│   - 生成 Python 代码来操作记忆树                        │
└──────────────────┬──────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────┐
│         可展开的树形记忆结构 (ExpandableTreeNode)        │
│                                                          │
│  Level 4 (Root): HigherLevelSummary                     │
│  ├─ "2024年7月: 完成了厨房清理和物品整理任务"            │
│  │  └─ children (collapsed) ...                         │
│  │                                                       │
│  ├─ Level 3: GoalBasedSummary (按目标聚合)              │
│  │  └─ "目标: 清理厨房"                                 │
│  │     └─ events (collapsed) ...                        │
│  │                                                       │
│  ├─ Level 2: EventBasedSummary (按事件聚合)             │
│  │  └─ "动作: 拿起杯子 <成功>"                          │
│  │     └─ scenes (collapsed) ...                        │
│  │                                                       │
│  ├─ Level 1: SceneGraphInstant (场景图)                 │
│  │  └─ "视觉观察: 桌子, 杯子 [空的]"                     │
│  │     └─ raw (collapsed) ...                           │
│  │                                                       │
│  └─ Level 0: RawDataInstant (原始数据)                  │
│     └─ image, timestamp, action_params, etc.            │
└──────────────────┬──────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────┐
│              语义搜索 (Sentence Embedding)               │
│   - 将查询和节点内容转为向量                             │
│   - 计算余弦相似度                                       │
│   - 返回最相关的节点索引                                 │
└──────────────────┬──────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────┐
│              展开/折叠操作 (expand/collapse)             │
│   - 只显示相关节点的详细信息                             │
│   - 保持其他节点折叠以减少上下文长度                     │
└──────────────────┬──────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────┐
│                  生成最终答案                            │
│   - 基于展开的相关节点                                   │
│   - 调用 api.answer("...")                              │
└─────────────────────────────────────────────────────────┘
```

---

### 3️⃣ 哪 3 个模块最关键？为什么？

#### 🔴 模块 1: `em_tree.py` - 分层记忆数据结构

**代码位置**: `em/em_tree.py`

**为什么关键**:
- 这是整个系统的**数据基础**
- 定义了 4 个层级的抽象（L0→L3+）
- 每个层级都有 `nl_summary`（自然语言摘要）和 `range`（时间范围）

**核心类**:
```python
# L0: 原始传感器数据
RawDataInstant: 时间戳 + 图像 + 动作 + 语音

# L1: 场景图（物体+关系）
SceneGraphInstant: objects + relations + raw

# L2: 基于事件的摘要（动作完成时刻）
EventBasedSummary: scenes[] + audio_description

# L3: 基于目标的摘要（目标完成/失败时刻）
GoalBasedSummary: events[] + explicit_goal

# L4+: 更高层次的摘要（自动生成）
HigherLevelSummary: nl_summary + children[]
```

**关键属性**:
- `.nl_summary`: 该节点的自然语言描述（供 LLM 阅读）
- `.range`: (start_time, end_time) 时间范围（用于时间查询）
- `.index_content`: 用于语义搜索的文本内容列表

---

#### 🔴 模块 2: `interactive_tree.py` - 可展开树节点

**代码位置**: `llm_emv/interactive_tree.py`

**为什么关键**:
- 这是系统的**核心创新**：动态展开/折叠
- 通过 Python 对象的 `__repr__` 控制 LLM 看到什么
- 实现了高效的上下文管理（只展开需要的部分）

**核心操作**:
```python
history.search("找杯子")        # 语义搜索，自动展开相关节点
history.expand(0, 5)            # 按索引展开
history.expand(datetime(...))   # 按时间展开
history.collapse()              # 折叠所有
history.collapse_deep()         # 递归折叠所有子节点
```

**折叠状态的表示**:
```python
# 折叠时：只显示 "..."
[0: "2024/07/01: 厨房清理任务", ...]

# 展开后：显示完整内容
[0: GoalBasedSummary(
    2024/07/01 14:00 - 14:30,
    "目标: 清理厨房 <成功>",
    children={...}
  ),
  ...]
```

---

#### 🔴 模块 3: `emv_api.py` + `setup.py` - LLM Agent 控制接口

**代码位置**: `llm_emv/emv_api.py`, `llm_emv/setup.py`

**为什么关键**:
- 这是 **LLM 和记忆系统之间的桥梁**
- 定义了 LLM 可以调用的 API
- 实现了搜索语义嵌入缓存（加速）

**核心 API**:
```python
api.history                  # 访问记忆树
api.history.search("...")    # 语义搜索
api.answer("...")            # 返回答案
api.now()                    # 当前时间
api.vqa(question, image)     # 视觉问答（可选）
```

**语义搜索机制** (`history_search_similarity`):
1. 预计算所有节点的嵌入向量（来自 `index_content`）
2. 计算查询和节点的余弦相似度
3. 使用 `top_p` 和 `min_cos_sim` 过滤结果
4. 返回最相关的节点索引

---

### 4️⃣ 哪些参数是"我不敢动的"？为什么？

#### 🔒 不要轻易改动的参数

| 参数位置 | 参数名 | 为什么不能动 | 影响 |
|---------|--------|-------------|------|
| `interactive_tree.py:308` | `top_p=0.5` | 控制搜索召回率 | 太小→找不到相关节点<br>太大→无关节点过多 |
| `interactive_tree.py:309` | `min_cos_sim=0.2` | 语义相似度阈值 | 太高→搜索失败<br>太低→噪音太多 |
| `setup.py:106` | `embedding='all-MiniLM-L6-v2'` | 嵌入模型 | 改了需要重新计算所有缓存 |
| `emv_api.py:26` | `hierarchy_level='deep'` | 树的层次模式 | 决定系统行为模式 |

#### ✅ 可以安全实验的参数

| 参数位置 | 参数名 | 实验价值 |
|---------|--------|---------|
| `config/*/full.yaml` | `temperature` | 观察 LLM 生成代码的随机性 |
| `interactive_tree.py:310-311` | `close_match_*` | 调整"精确搜索"模式的行为 |
| `config/*/system.prompt.txt` | system prompt | 改变 Agent 的搜索策略 |

---

### 5️⃣ 我现在这个结果，和论文差异可能来自哪？

#### 可能的差异来源（优先级排序）

1. **LLM 版本差异** 🔴
   - 论文可能用的是 GPT-4-turbo 的某个快照版本
   - OpenAI 的模型会持续更新，行为可能变化
   - **检查方法**: 对比论文发表时间和你使用的模型版本

2. **数据预处理差异** 🟡
   - 场景图生成（物体检测）可能有随机性
   - 更高层次的摘要可能需要额外的 LLM 调用生成
   - **检查方法**: 看 `data/` 下的 `.pkl` 文件是否和论文一致

3. **评估指标计算** 🟡
   - BLEU/ROUGE 的实现细节可能不同
   - LLM-based 评估有随机性
   - **检查方法**: 读 `llm_emv/eval/metrics/` 的代码

4. **缓存影响** 🟢
   - LangChain 的缓存可能影响结果
   - 嵌入缓存正常不应该影响
   - **检查方法**: 删除 `langchain-cache.db` 重新运行

---

## 🛠️ 复现步骤（手把手）

### Step 1: 环境搭建

```bash
# 1. 创建虚拟环境
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# 2. 安装依赖
pip install -r requirements.txt

# 3. 配置 OpenAI API Key
# Windows PowerShell:
$env:OPENAI_API_KEY="your-api-key-here"
# Linux/Mac:
# export OPENAI_API_KEY="your-api-key-here"

# 或者创建 .env 文件（推荐）
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

### Step 2: 理解预处理数据

```bash
# 检查数据文件
dir data\armarx_lt_mem\

# 主要文件：
# - 2024-a7a-merged-summary.pkl  <- 这是完整的记忆树
# - qa.json                      <- 问答评估数据
```

**数据结构探索**（在 Python 中）:
```python
import pickle
from pathlib import Path

# 加载记忆树
history_path = Path('data/armarx_lt_mem/2024-a7a-merged-summary.pkl')
history = pickle.loads(history_path.read_bytes())

# 查看结构
print(f"类型: {type(history)}")
print(f"时间范围: {history.range}")
print(f"顶层摘要:\n{history.nl_summary}")
print(f"子节点数量: {len(history.children)}")

# 递归查看深度
def count_depth(node):
    if not hasattr(node, 'children'):
        return 0
    if len(node.children) == 0:
        return 0
    return 1 + max(count_depth(c) for c in node.children)

print(f"树的深度: {count_depth(history)}")
```

### Step 3: 运行交互式问答

```bash
# 运行交互式系统
python -m llm_emv --config armarx_lt_mem/full

# 系统启动后，你会看到：
# Top-level waiting for trigger...
# User:

# 试着问几个问题：
# - "机器人昨天做了什么？"
# - "找到所有拿杯子的时刻"
# - "2024年7月1日发生了什么？"
```

**观察要点**:
- LLM 生成了什么 Python 代码？
- 调用了 `api.history` 的哪些方法？
- `search()` 返回了哪些节点？
- 最终答案是基于哪些展开的节点？

### Step 4: 运行评估实验

```bash
# 在 armarx 数据集上运行评估
python -m llm_emv.eval \
  --cfg armarx_lt_mem/full \
  --dataset simple \
  --output experiments/results/my_run.json

# 查看结果
python -m llm_emv.eval.metrics.calc_metrics \
  experiments/results/my_run.json
```

### Step 5: 核心机制分析实验

**实验 A: 搜索机制的影响**

1. 禁用搜索（只用展开）
2. 改变搜索阈值
3. 观察性能变化

```python
# 修改 config/armarx_lt_mem/full.yaml
search:
  filter_kwargs:
    min_cos_sim: 0.1  # 原来是 0.2，降低看效果
```

**实验 B: 层次结构的影响**

```bash
# 对比不同的 hierarchy_level
--cfg armarx_lt_mem/predefined  # 只用 L3
--cfg armarx_lt_mem/full        # 完整层次 (deep)
```

---

## 🧠 5 个元问题框架（挂载知识）

### ① 世界是怎么被表示的？（Representation）

**这个系统中**:
- **原始层（L0）**: 图像、音频、动作参数
- **符号层（L1）**: 场景图（物体+关系）
- **语言层（L2-L4）**: 自然语言摘要 + 时间范围
- **向量层**: Sentence Embeddings（用于搜索）

**为什么这样设计**:
- 图像太大，不能全给 LLM → 用场景图压缩
- 场景图太细，不能全给 LLM → 用 NL 摘要抽象
- 摘要太多，不能全给 LLM → 用分层+折叠

---

### ② 模型在"做什么计算"？（Computation）

**LLM 部分**:
- **输入**: System Prompt + 用户问题 + 当前展开的记忆树
- **输出**: Python 代码（操作记忆树）
- **计算类型**: Code Generation + Planning

**搜索部分**:
- **输入**: 查询文本 + 所有节点的 index_content
- **输出**: 相关节点的索引
- **计算类型**: 余弦相似度（向量检索）

---

### ③ 学习信号从哪来？（Learning Signal）

**这个系统不需要训练！**（Zero-shot / Few-shot）

- LLM: 预训练的 GPT-4（Frozen）
- Embedding Model: 预训练的 SentenceTransformer（Frozen）
- 唯一需要"生成"的是高层摘要（L3+ 以上），通过 LLM 生成

**如果要改进**:
- 可以在 prompt 中加入 few-shot examples（见 `config/teach/` 的例子）
- 可以 fine-tune 嵌入模型来提高搜索准确率

---

### ④ 记忆在哪里？怎么更新？（Memory）

**外部记忆（主要）**:
- 记忆树存储在 Python 对象中（内存）
- 持久化为 `.pkl` 文件（磁盘）
- 嵌入向量缓存为 `.pt` 文件（加速）

**参数记忆（辅助）**:
- LLM 的参数内存（隐式知识）
- 用于理解问题、生成代码、推理

**更新机制**:
- **离线构建**: 记忆树是预先构建好的（不是在线的）
- **增量更新**: 理论上可以追加新节点（代码支持）

---

### ⑤ 系统约束是什么？（Constraint）

| 约束类型 | 具体限制 | 影响 |
|---------|---------|------|
| **LLM Context Window** | GPT-4 最多 128K tokens | 不能一次展开整个树 |
| **API 成本** | 每次调用 $0.01-0.03 | 需要缓存 + 最小化展开 |
| **搜索速度** | 每次搜索几秒钟 | 预计算嵌入 + 缓存 |
| **内存占用** | 几个月数据 ~1GB | 需要懒加载图像 |

**设计如何应对**:
- 分层折叠 → 控制上下文长度
- 语义搜索 → 快速定位相关部分
- 嵌入缓存 → 避免重复计算
- 懒加载图像 → 减少内存占用

---

## 🎯 你的下一步行动（2 周计划）

### ✅ 第 1 周：建立系统骨架认知

**Day 1-2**: 环境 + 数据探索
- [ ] 安装依赖，运行一次交互式系统
- [ ] 用 Python 脚本加载并可视化记忆树结构
- [ ] 画出你自己理解的系统图（手绘也行）

**Day 3-4**: 代码结构阅读
- [ ] 阅读 `em_tree.py`，理解 4 个层级
- [ ] 阅读 `interactive_tree.py`，理解展开/折叠
- [ ] 阅读 `emv_api.py`，理解 LLM 能调用什么

**Day 5-7**: 跑通评估
- [ ] 运行完整评估流程（至少 5 个样本）
- [ ] 对比你的结果和论文中的数字
- [ ] 记录差异和可能原因

---

### ✅ 第 2 周：从按钮到实验

**Week 2 目标**: 改一个东西，看看发生了什么

**实验 1: 搜索阈值的影响**
```python
# 修改 interactive_tree.py:309
min_cos_sim: 0.1  # 从 0.2 降到 0.1

# 问题：
# - 搜索召回率变化了多少？
# - 答案质量变化了吗？
# - API 成本变化了吗？
```

**实验 2: 禁用语义搜索**
```python
# 修改 setup.py，传入 search_embedding_fn=None
# 强制 LLM 只能用 expand() 而不能用 search()

# 问题：
# - LLM 还能完成任务吗？
# - 需要多少步才能找到答案？
# - 成本增加了多少？
```

**实验 3: 改变层次模式**
```bash
# 对比三种模式：
--config armarx_lt_mem/predefined  # 只用 L3（最粗粒度）
--config armarx_lt_mem/full        # 完整层次
--config armarx_lt_mem/zs_1pass_flat  # 完全扁平（baseline）

# 问题：
# - 哪个模式最准确？
# - 哪个模式最便宜？
# - 为什么？
```

---

## 📚 深入阅读建议

### 如果你想理解"为什么这样设计"

1. **读论文的相关工作部分**（Related Work）
   - 看看别人怎么做长时记忆的
   - 为什么他们的方法不 scale

2. **读论文的 Ablation Study**
   - Table 2: 不同层次结构的对比
   - Table 3: 搜索机制的影响
   - 这些实验告诉你"哪些设计是关键的"

### 如果你想理解"这个方向未来怎么走"

1. **读论文的 Limitations 和 Future Work**
2. **思考**: 这个系统还不能做什么？
   - 在线学习（现在是离线的）
   - 跨模态检索（现在主要是文本）
   - 个性化（现在是通用的）

---

## ⚠️ 常见坑点提醒

### 坑 1: 缓存导致的困惑
**症状**: 改了代码但结果没变
**原因**: LangChain 缓存了 LLM 的输出
**解决**: 删除 `langchain-cache.db`

### 坑 2: API Key 用尽
**症状**: 运行到一半报错 "Rate limit exceeded"
**原因**: OpenAI API 有速率限制
**解决**: 在 `eval/__main__.py` 加入重试逻辑，或降低并发

### 坑 3: 内存爆炸
**症状**: 运行时内存占用越来越大
**原因**: 嵌入缓存 + 图像加载
**解决**: 使用 `LazyLoadPILImage`（已经用了），或减少样本数量

### 坑 4: 结果不可复现
**症状**: 每次运行结果都不一样
**原因**: LLM 的 temperature > 0
**解决**: 在配置文件中设置 `temperature: 0`

---

## 🎓 总结：你现在应该有的认知

### 系统的"一句话本质"
> **这是一个用 LLM 作为控制器，通过动态展开/折叠来高效检索分层记忆的系统**

### 三个关键设计
1. **分层抽象**：L0（原始）→ L1（符号）→ L2（事件）→ L3（目标）→ L4+（摘要）
2. **按需展开**：只展开相关部分，保持上下文可控
3. **语义搜索**：用嵌入向量快速定位相关节点

### 下一步你要做什么
1. **Week 1**: 把系统跑起来，理解数据流
2. **Week 2**: 改一个参数，做对比实验
3. **之后**: 基于这个框架，思考你的毕设/开题可以怎么改进

---

## 🤝 我能继续帮你什么？

现在我可以：
1. **帮你写实验脚本**（自动化对比不同配置）
2. **帮你分析评估结果**（读取 JSON 并可视化）
3. **帮你设计改进方案**（基于你的研究兴趣）
4. **解答任何代码细节问题**（逐行讲解都可以）

**你现在最想做哪一个？**

或者，如果你想直接开始，告诉我：
- 你的 OPENAI_API_KEY 配置好了吗？
- 你想先跑交互式系统还是评估实验？
- 有没有特别不理解的代码部分？

我会根据你的节奏调整，**从按钮到实验**，我们一步步来！

